Este trabalho apresenta uma análise teórica e empírica de algoritmos de ordenação interna, uma operação fundamental da ciência da computação com aplicações em diversas áreas. O objetivo é comparar o desempenho de 14 algoritmos de ordenação, classificados em métodos inferiores, superiores, híbridos e de tempo linear. A metodologia compreende a implementação desses algoritmos na linguagem C e a execução de testes controlados utilizando vetores com até $10^8$ elementos, sob distribuições ordenada, decrescente e pseudoaleatória. O estudo coletou métricas de tempo de execução, número de comparações, movimentações de dados e eficiência de cache do processador. Os resultados empíricos demonstram que o Quicksort aleatorizado e o Introsort apresentam o melhor desempenho geral entre os métodos baseados em comparação, enquanto algoritmos lineares, como o Countingsort e o Radixsort, superam os demais em cenários específicos, apesar do maior consumo de memória. A análise destaca a importância da hierarquia de memória, evidenciando que algoritmos com boa localidade de referência otimizam significativamente a ordenação de grandes volumes de dados. O trabalho conclui que a escolha do algoritmo ideal exige uma análise multidimensional que considere as características do hardware e a natureza da distribuição dos dados, uma vez que a análise assintótica isolada não prevê o impacto das falhas de cache no tempo de execução real.

\palavraschave{Ordenação; Algoritmos; Análise empírica; Complexidade; Eficiência de cache.}
